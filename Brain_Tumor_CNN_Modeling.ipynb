{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82211879",
   "metadata": {},
   "source": [
    "# Brain Tumor Classifier Using Convolutional Neural Network (CNN)\n",
    "\n",
    "## Business Understanding\n",
    "According to the [National Brain Tumor Society](https://braintumor.org/brain-tumors/about-brain-tumors/brain-tumor-facts/), approximately 700,000 individuals in the United States are living with a primary brain tumor. In 2023, over 94,000 people are expected to be diagnosed with a brain tumor, and more than 18,000 will succumb to the disease. Even \"benign\" tumors can significantly impact a patient's quality of life, while malignant tumors like gliomas can often be fatal.\n",
    "\n",
    "Accurate tumor classification is crucial for effective treatment. However, the [National Cancer Institute](https://www.cancer.gov/rare-brain-spine-tumor/blog/2020/brain-tumors-diagnosed-treated) reports that as of 2020, 5-10% of brain tumor diagnoses are incorrect. This may be due to the vast number of brain tumor types, as [classified by the World Health Organization](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8328013/). A well-trained deep learning model on MRI images from various brain tumors could be a valuable tool for clinicians.\n",
    "\n",
    "Current deep learning models typically focus on three tumor types (pituitary, meningioma, and glioma) due to limited MRI image availability. Some models also include a \"healthy\" or \"no tumor\" category. While there is some publicly available data for other tumor types, the sample sizes are often too small for effective deep learning. This project aims to enhance existing models by adding an \"other tumor\" class, encompassing images from patients with rarer tumor types.\n",
    "\n",
    "An accurate tumor classification model trained on a broader dataset could be highly beneficial to stakeholders such as American College of Radiology-accredited facilities, which encounter patients with a wide variety of tumor types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2e4f317d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "# For Data Processing And Evaluation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# For ML Models\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import Accuracy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import load_img, ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import layers\n",
    "from keras.models import Model\n",
    "\n",
    "# For Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Miscellaneous\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Suppress future, deprecation, and SettingWithCopy warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category= FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# make all columns in a df viewable and wider\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.width = None\n",
    "pd.set_option('max_colwidth', 400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bbd8d",
   "metadata": {},
   "source": [
    "## Data Understanding and Preparation\n",
    "I used two datasets:\n",
    "- 7,023 total T1C-enhanced MRI images of pituitary, meningioma, and glioma, as well as images of brains with no tumors.  These images are from a [dataset available on Kaggle from Masoud Nickparvar.](https://www.kaggle.com/datasets/masoudnickparvar/brain-tumor-mri-dataset)\n",
    "- A subset of 1,177 \"other\" tumor MRI images from a [dataset available on Kaggle from Fernando Feltrin.](https://www.kaggle.com/datasets/fernando2rad/brain-tumor-mri-images-44c) In constructing this \"other\" class.\n",
    "\n",
    "The use of this second dataset is what allowed me to construct the \"other\" category, which differentiates this model from many other proposed approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a4e31a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify local directories for training and testing data\n",
    "train_dir = 'data/Training/'\n",
    "test_dir = 'data/Testing/'\n",
    "\n",
    "# Create a new directory named \"other\" in the train directory\n",
    "new_train_dir = os.path.join(train_dir, 'other')\n",
    "if not os.path.exists(new_train_dir):\n",
    "    os.makedirs(new_train_dir)\n",
    "\n",
    "# Create a new directory named \"other\" in the test directory\n",
    "new_test_dir = os.path.join(test_dir, 'other')\n",
    "if not os.path.exists(new_test_dir):\n",
    "    os.makedirs(new_test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "76d1b16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify folders with images to move from second dataset\n",
    "supplement_labels = ['Astrocitoma T1C+', 'Carcinoma T1C+', 'Ependimoma T1C+', 'Ganglioglioma T1C+',\n",
    "                'Germinoma T1C+', 'Granuloma T1C+', 'Meduloblastoma T1C+', 'Neurocitoma T1C+',\n",
    "                'Oligodendroglioma T1C+', 'Papiloma T1C+', 'Schwannoma T1C+', 'Tuberculoma T1C+']\n",
    "\n",
    "# specify path with images from second dataset\n",
    "supplement_path = 'data/supplement/'\n",
    "\n",
    "# move 80% of images to the new \"other\" directory in train_dir and 20% to the new \"other\" directory in test_dir\n",
    "for label in supplement_labels:\n",
    "    folder_path = os.path.join(supplement_path, label)\n",
    "    files = os.listdir(folder_path)\n",
    "    random.shuffle(files)\n",
    "    num_files = len(files)\n",
    "    num_train_files = int(num_files * 0.8)\n",
    "    train_files = files[:num_train_files]\n",
    "    test_files = files[num_train_files:]\n",
    "    files_moved = 0\n",
    "    \n",
    "    for filename in train_files:\n",
    "        if filename.endswith((\".jpg\", \".jpeg\")):\n",
    "            src_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(src_path):\n",
    "                dst_path = os.path.join(new_train_dir, filename)\n",
    "                shutil.move(src_path, dst_path)\n",
    "\n",
    "    for filename in test_files:\n",
    "        if filename.endswith((\".jpg\", \".jpeg\")):\n",
    "            src_path = os.path.join(folder_path, filename)\n",
    "            if os.path.isfile(src_path):\n",
    "                dst_path = os.path.join(new_test_dir, filename)\n",
    "                shutil.move(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4236c5",
   "metadata": {},
   "source": [
    "Now that the images are all in the right place, we can create our training and test sets. We'll make corresponding lists of filepaths and labels, and store the information in a DataFrame to use in our ImageDataGenerators later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c07f431f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# list of labels corresponding to folders\n",
    "labels = ['pituitary', 'notumor', 'meningioma', 'glioma', 'other']\n",
    "\n",
    "# initialize empty lists\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "# add filepaths and labels to train lists\n",
    "for label in labels:\n",
    "    for image in os.listdir(train_dir+label):\n",
    "        X_train.append(train_dir+label+'/'+image)\n",
    "        y_train.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31bfeed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize empty lists\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "# add filepaths and labels to test lists\n",
    "for label in labels:\n",
    "    for image in os.listdir(test_dir+label):\n",
    "        X_test.append(test_dir+label+'/'+image)\n",
    "        y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f2300606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle lists\n",
    "X_train, y_train = shuffle(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29ad045",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create dataframe for later use\n",
    "tumor_train_df = pd.concat([pd.Series(X_train, name = 'paths'), \n",
    "                            pd.Series(y_train, name = 'label')], \n",
    "                            axis = 1)\n",
    "tumor_train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "088c8820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle lists\n",
    "X_test, y_test = shuffle(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a326ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create dataframe for later use\n",
    "tumor_test_df = pd.concat([pd.Series(X_test, name = 'paths'), \n",
    "                            pd.Series(y_test, name = 'label')], \n",
    "                            axis = 1)\n",
    "tumor_test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a810da7",
   "metadata": {},
   "source": [
    "Now that we have training and test DataFrames, let's take a look at some of the characteristics of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855a4c08",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a778fc",
   "metadata": {},
   "source": [
    "Let's look at the distribution of our target variable - tumor types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac465af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tumor_train_df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4c1099",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# instantiate figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot histogram of tumor types\n",
    "tumor_train_df['label'].value_counts().plot(kind = 'bar')\n",
    "\n",
    "#set title and axis labels\n",
    "ax.set_title('Distribution of tumor type in training data')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Tumor Type');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c259b3e",
   "metadata": {},
   "source": [
    "Our training classes are slightly imbalanced, but not terribly so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2385c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_test_df['label'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b7b25e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# instantiate figure\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot tumor types\n",
    "tumor_test_df['label'].value_counts().plot(kind = 'bar')\n",
    "\n",
    "# set title and axis labels\n",
    "ax.set_title('Distribution of tumor type in test data')\n",
    "ax.set_ylabel('Count')\n",
    "ax.set_xlabel('Tumor Type');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c37279e",
   "metadata": {},
   "source": [
    "The test data is the same - imbalanced, but not alarmingly so. Based on this distribution of classes, we would expect a naive model that simply predicts the majority class every time to achieve an accuracy of about 26%.\n",
    "\n",
    "Let's take a look at some of these MRI images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99ab77",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with gratitude to MD Mushfirat Mohaimin for this code\n",
    "# https://www.kaggle.com/code/mushfirat/brain-tumor-classification-accuracy-96\n",
    "\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "def open_images(paths):\n",
    "    '''\n",
    "    Given a list of paths to images, this function returns the images as arrays.\n",
    "    '''\n",
    "    images = []\n",
    "    for path in paths:\n",
    "        image = load_img(path, target_size=IMAGE_SIZE)\n",
    "        image = np.array(image)\n",
    "        images.append(image)\n",
    "    return np.array(images)\n",
    "\n",
    "# open 16 images\n",
    "images = open_images(X_train[50:67])\n",
    "labels = y_train[50:67]\n",
    "fig = plt.figure(figsize=(12, 16))\n",
    "for x in range(1, 17):\n",
    "    fig.add_subplot(4, 4, x)\n",
    "    plt.axis('off')\n",
    "    plt.title(labels[x-1])\n",
    "    plt.imshow(images[x-1])\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510d7fc",
   "metadata": {},
   "source": [
    "They appears to be taken from different angles, but are all grayscale. The images with tumors of any kind appear distinct from images with no tumors, which makes sense. Pituitary tumors seem localized in one spot (the pituitary gland, at the base of the brain), whereas gliomas, meningiomas, and other tumors are distributed elsewhere in the brain. Let's construct a simple baseline model as a starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc1e512",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927c9bfe",
   "metadata": {},
   "source": [
    "For this model, we will use a single dense layer with 32 nodes before our output layer. We will not perform any image augmentation for now - we just want to get the simplest possible baseline sense of the model's accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c928733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale images\n",
    "train_datagen_baseline = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen_baseline = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32\n",
    "\n",
    "# generate image data from training df\n",
    "train_generator_baseline = train_datagen_baseline.flow_from_dataframe(\n",
    "        tumor_train_df,\n",
    "        x_col = 'paths',\n",
    "        y_col = 'label',\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale',\n",
    "        seed = 1990,\n",
    "        shuffle = False)\n",
    "\n",
    "# generate image data from test df\n",
    "test_generator_baseline = test_datagen_baseline.flow_from_dataframe(\n",
    "        tumor_test_df,\n",
    "        x_col = 'paths',\n",
    "        y_col = 'label',\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale',\n",
    "        seed = 1990,\n",
    "        shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c072b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify hyperparamters for model\n",
    "cce = keras.losses.CategoricalCrossentropy()\n",
    "opt = keras.optimizers.Adam()\n",
    "es = EarlyStopping(monitor='loss', patience=5)\n",
    "\n",
    "# define learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    lr = .001\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "    \n",
    "sched = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4cc431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model and add dense layer and output layer\n",
    "model = Sequential()\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model.compile(optimizer=opt, loss=cce,  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2edfbc3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model = model.fit(train_generator_baseline,\n",
    "                       verbose = 1,\n",
    "                       validation_data = test_generator_baseline, \n",
    "                       epochs=50,\n",
    "                       callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245bd36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac56238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(base_model.history['accuracy'])\n",
    "plt.plot(base_model.history['val_accuracy'])\n",
    "plt.title('Model Accuracy - Baseline')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(base_model.history['loss'])\n",
    "plt.plot(base_model.history['val_loss'])\n",
    "plt.title('Model Loss - Baseline')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455f72b7",
   "metadata": {},
   "source": [
    "The model peaked at around 66% accuracy on test data, which is better than a naive model but not nearly good enough to be deployed in clinical practice. It is also badly overfit to the training data. We can likely improve on this accuracy by augmenting our training data, and adding layers to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12922325",
   "metadata": {},
   "source": [
    "## Data Augmentation and Second Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df61e28",
   "metadata": {},
   "source": [
    "For this second model, we'll augment our training images by flipping them horizontally and vertically; adjusting the brightness of images to make them darker or brighter; and rotating them slightly to account for potential rotational differences in test images. We won't perform any augmentation on the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996778e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate generators with augmentation for training data\n",
    "train_datagen_aug = ImageDataGenerator(rescale=1./255,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True,\n",
    "                                       brightness_range=[0.75, 1.25],\n",
    "                                       rotation_range = 15)\n",
    "test_datagen_aug = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# generate image data\n",
    "train_generator_aug = train_datagen_aug.flow_from_dataframe(\n",
    "        tumor_train_df,\n",
    "        x_col = 'paths',\n",
    "        y_col = 'label',\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale',\n",
    "        seed = 1990,\n",
    "        shuffle = False)\n",
    "\n",
    "# generate image data\n",
    "test_generator_aug = test_datagen_aug.flow_from_dataframe(\n",
    "        tumor_test_df,\n",
    "        x_col = 'paths',\n",
    "        y_col = 'label',\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        color_mode='grayscale',\n",
    "        seed = 1990,\n",
    "        shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfe4560",
   "metadata": {},
   "source": [
    "For this model, we'll add in an additional dense layer, but more importantly we will add in two convolutional and pooling layers. Convolutional layers aid in feature extraction (such as edge detection) by using a defined filter to recognize patterns in the image. Max pooling layers are used to downsample the input image by taking only the maximum value from the defined window, which helps to consolidate the features learned by the convolutional layers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "97cd916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = Sequential()\n",
    "\n",
    "# define 3x3 filter window sizes and create 64 filters\n",
    "model_conv.add(layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                        input_shape=(224, 224, 1)))\n",
    "# max pool in 2x2 window\n",
    "model_conv.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# define 3x3 filter window sizes and create 128 filters\n",
    "model_conv.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "# max pool in 2x2 window\n",
    "model_conv.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_conv.add(layers.Flatten())\n",
    "\n",
    "# add dense layers and output layer\n",
    "model_conv.add(layers.Dense(128, activation='relu'))\n",
    "model_conv.add(layers.Dense(64, activation='relu'))\n",
    "model_conv.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# compile and fit model\n",
    "model_conv.compile(optimizer=opt, loss=cce,  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b3d132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d9ad84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_model = model_conv.fit(train_generator_aug,\n",
    "                       verbose = 1,\n",
    "                       validation_data = test_generator_aug, \n",
    "                       epochs=50,\n",
    "                       callbacks = [es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b152cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(conv_model.history['accuracy'])\n",
    "plt.plot(conv_model.history['val_accuracy'])\n",
    "plt.title('Model Accuracy - Simple CNN')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(conv_model.history['loss'])\n",
    "plt.plot(conv_model.history['val_loss'])\n",
    "plt.title('Model Loss - Simple CNN')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b89147",
   "metadata": {},
   "source": [
    "As we can see, the accuracy rose for this model from the baseline considerably - from 66% to nearly 91%. We also reduced the overfitting observed in the baseline model, though not completely. Our next model will focus on trying to eliminate overfitting altogether."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97057b87",
   "metadata": {},
   "source": [
    "## Model 3: With Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c57c975",
   "metadata": {},
   "source": [
    "We'll add some regularization to this model in the form of batch normalization, which makes the values in each layer more stable; dropout layers, which randomly set some of the outputs from the previous layer to zero during each epoch to encourage the network to learn more about more robust features and less about features of specific inputs; and kernel regularization applied to the convolutional layers, which functions similarly to the regularization penalties applied to other models. We'll also use a learning rate scheduler going forward, which automatically decays the value of the learning rate starting at a specified epoch to ensure changes made to the model weights later in the training process are smaller and thus less likely to result in overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d52c3937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify level of regularization\n",
    "reg = l2(1e-2)\n",
    "\n",
    "# instantiate model\n",
    "model_conv_drop = Sequential()\n",
    "\n",
    "# first conv layer\n",
    "model_conv_drop.add(layers.Conv2D(64, (3, 3), activation='relu',\n",
    "                        input_shape=(224, 224, 1), kernel_regularizer = reg))\n",
    "model_conv_drop.add(BatchNormalization())\n",
    "model_conv_drop.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# second conv layer\n",
    "model_conv_drop.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer = reg))\n",
    "model_conv_drop.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "model_conv_drop.add(layers.Flatten())\n",
    "\n",
    "# dense layers and output layer\n",
    "model_conv_drop.add(layers.Dense(128, activation='relu'))\n",
    "model_conv_drop.add(Dropout(0.3))\n",
    "model_conv_drop.add(layers.Dense(64, activation='relu'))\n",
    "model_conv_drop.add(layers.Dense(32, activation='relu'))\n",
    "model_conv_drop.add(layers.Dense(5, activation='softmax'))\n",
    "\n",
    "# compile model\n",
    "model_conv_drop.compile(optimizer=opt, loss=cce,  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5082310",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_conv_drop.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da89f655",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conv_drop_model = model_conv_drop.fit(train_generator_aug,\n",
    "                       verbose = 1,\n",
    "                       validation_data = test_generator_aug, \n",
    "                       epochs=50,\n",
    "                       callbacks = [es, sched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf48944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(conv_drop_model.history['accuracy'])\n",
    "plt.plot(conv_drop_model.history['val_accuracy'])\n",
    "plt.title('Model Accuracy - CNN W/ Normalization')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(conv_drop_model.history['loss'])\n",
    "plt.plot(conv_drop_model.history['val_loss'])\n",
    "plt.title('Model Loss - CNN W/ Normalization')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab09c4a",
   "metadata": {},
   "source": [
    "The performance seems to have remained about the same from that of the prior model. Let's try a deeper model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab487c08",
   "metadata": {},
   "source": [
    "## Transfer Learning - VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0dde1b",
   "metadata": {},
   "source": [
    "Transfer learning is the use of a model developed for one task in a separate task. In this case, I will use the VGG-16 model, which is a 16-layer CNN originally developed for the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) computer vision competition. There are two approaches to transfer learning - the model can be \"frozen\" with its existing weights and used purely for feature extraction before the dense and output layers are added on, or parts can be \"unfrozen\" and fine-tuned on new data. I will start with the first approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f5f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate generators with augmentation and preprocessing for training data\n",
    "train_datagen_vgg = ImageDataGenerator(rescale=1./255,\n",
    "                                       preprocessing_function=keras.applications.vgg16.preprocess_input,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True,\n",
    "                                       brightness_range=[0.75, 1.25],\n",
    "                                       rotation_range = 15)\n",
    "test_datagen_vgg = ImageDataGenerator(rescale=1./255, \n",
    "                                      preprocessing_function=keras.applications.vgg16.preprocess_input)\n",
    "\n",
    "# generate image data for training set\n",
    "train_generator_vgg = train_datagen_vgg.flow_from_dataframe(\n",
    "        tumor_train_df,\n",
    "        x_col = 'paths',\n",
    "        y_col = 'label',\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        seed = 1990,\n",
    "        shuffle = False)\n",
    "\n",
    "# generate image data for test set\n",
    "test_generator_vgg = test_datagen_vgg.flow_from_dataframe(\n",
    "        tumor_test_df,\n",
    "        x_col = 'paths',\n",
    "        y_col = 'label',\n",
    "        target_size=IMAGE_SIZE,\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        seed = 1990,\n",
    "        shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b98471",
   "metadata": {},
   "source": [
    "## Model 4: Frozen VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0d81d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate vgg model\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "output = vgg.layers[-1].output\n",
    "output = layers.Flatten()(output)\n",
    "vgg_model = Model(vgg.input, output)\n",
    "\n",
    "# freeze layers\n",
    "vgg_model.trainable = False\n",
    "for layer in vgg_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "input_shape = vgg_model.output_shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1437ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model summary\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe5315e",
   "metadata": {},
   "source": [
    "As we can see, the model has over 14 million parameters - but none of them are trainable! Let's try fitting it to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82d87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "vggmodel = Sequential()\n",
    "\n",
    "# add vgg layers\n",
    "vggmodel.add(vgg_model)\n",
    "vggmodel.add(layers.Flatten())\n",
    "\n",
    "# add dense layers and output layer\n",
    "vggmodel.add(Dense(512, activation='relu', input_dim=input_shape))\n",
    "vggmodel.add(Dropout(0.3))\n",
    "vggmodel.add(Dense(512, activation='relu'))\n",
    "vggmodel.add(Dropout(0.3))\n",
    "vggmodel.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# compile and fit\n",
    "vggmodel.compile(optimizer=opt, loss=cce,  metrics=['accuracy'])\n",
    "vgg_model_feats = vggmodel.fit(train_generator_vgg,\n",
    "                       verbose = 1,\n",
    "                       validation_data = test_generator_vgg, \n",
    "                       epochs=50,\n",
    "                       callbacks = [es, sched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a32efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(vgg_model_feats.history['accuracy'])\n",
    "plt.plot(vgg_model_feats.history['val_accuracy'])\n",
    "plt.title('Model Accuracy - VGG Frozen')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(vgg_model_feats.history['loss'])\n",
    "plt.plot(vgg_model_feats.history['val_loss'])\n",
    "plt.title('Model Loss - VGG Frozen')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6276948b",
   "metadata": {},
   "source": [
    "This model performed the best of any so far, peaking at over 93% accuracy. Let's try fine-tuning it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeea167",
   "metadata": {},
   "source": [
    "### Model 5: VGG With Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fca9fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate vgg model\n",
    "vgg = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "output = vgg.layers[-1].output\n",
    "output = layers.Flatten()(output)\n",
    "vgg_model_finetune = Model(vgg.input, output)\n",
    "input_shape = vgg_model_finetune.output_shape[1]\n",
    "\n",
    "# set last convolutional layer to trainable\n",
    "vgg_model_finetune.trainable = True\n",
    "set_trainable = False\n",
    "for layer in vgg_model_finetune.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77164cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# examine model summary\n",
    "vgg_model_finetune.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310748b9",
   "metadata": {},
   "source": [
    "Now we can see that about half of the parameters are trainable. Let's try fitting the model to our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6cb7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "vggmodel_finetune = Sequential()\n",
    "\n",
    "# add VGG layers\n",
    "vggmodel_finetune.add(vgg_model_finetune)\n",
    "\n",
    "vggmodel_finetune.add(layers.Flatten())\n",
    "\n",
    "# add dense layers and output layer\n",
    "vggmodel_finetune.add(Dense(512, activation='relu', input_dim=input_shape))\n",
    "vggmodel_finetune.add(Dropout(0.3))\n",
    "vggmodel_finetune.add(Dense(512, activation='relu'))\n",
    "vggmodel_finetune.add(Dropout(0.3))\n",
    "vggmodel_finetune.add(Dense(5, activation='softmax'))\n",
    "\n",
    "# compile and fit model\n",
    "vggmodel_finetune.compile(optimizer=opt, loss=cce,  metrics=['accuracy'])\n",
    "finetune_vgg = vggmodel_finetune.fit(train_generator_vgg,\n",
    "                       verbose = 1,\n",
    "                       validation_data = test_generator_vgg, \n",
    "                       epochs=50,\n",
    "                       callbacks = [es, sched])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b97f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(finetune_vgg.history['accuracy'])\n",
    "plt.plot(finetune_vgg.history['val_accuracy'])\n",
    "plt.title('Model Accuracy - VGG Fine-Tuned')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(finetune_vgg.history['loss'])\n",
    "plt.plot(finetune_vgg.history['val_loss'])\n",
    "plt.title('Model Loss - VGG Fine-Tuned')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a402405",
   "metadata": {},
   "source": [
    "Again, this model performed similarly to the simple CNN. Let's take a closer look at the performance of the simple CNN, regularized CNN, and both VGG-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcd42ab",
   "metadata": {},
   "source": [
    "## Model Comparison and Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9afd798",
   "metadata": {},
   "source": [
    "To examine the results of each model, we'll need to generate predictions for our test data and compare them to the true classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723b433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate predictions for three top models\n",
    "y_pred_conv = model_conv.predict(test_generator_aug, batch_size = batch_size)\n",
    "y_pred_conv_drop = model_conv_drop.predict(test_generator_aug, batch_size = batch_size)\n",
    "y_pred_vgg = vggmodel.predict(test_generator_vgg)\n",
    "y_pred_vgg_finetune = vggmodel_finetune.predict(test_generator_vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "456b075c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify true and predicted classes for each model\n",
    "y_pred_classes_conv = np.argmax(y_pred_conv, axis=1)\n",
    "y_true_classes_conv = test_generator_aug.classes\n",
    "y_pred_classes_conv_drop = np.argmax(y_pred_conv_drop, axis=1)\n",
    "y_true_classes_conv_drop = test_generator_aug.classes\n",
    "y_pred_classes_vgg = np.argmax(y_pred_vgg, axis=1)\n",
    "y_true_classes_vgg = test_generator_vgg.classes\n",
    "y_pred_classes_vgg_finetune = np.argmax(y_pred_vgg_finetune, axis=1)\n",
    "y_true_classes_vgg_finetune = test_generator_vgg.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68ba190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm order of classes for each generator\n",
    "print(test_generator_aug.class_indices.keys())\n",
    "print(test_generator_vgg.class_indices.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43ef1da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# instantiate figure\n",
    "fig, axes = plt.subplots(figsize = (16, 16), ncols = 2, nrows = 2)\n",
    "report_labels = ['glioma', 'meningioma', 'notumor', 'other', 'pituitary']\n",
    "\n",
    "# plot confusion matrices for each model\n",
    "ConfusionMatrixDisplay.from_predictions(y_true_classes_conv, y_pred_classes_conv, \n",
    "                                        display_labels = report_labels,\n",
    "                                        xticks_rotation = 90,\n",
    "                                        ax = axes[0, 0])\n",
    "ConfusionMatrixDisplay.from_predictions(y_true_classes_conv_drop, y_pred_classes_conv_drop, \n",
    "                                        display_labels = report_labels,\n",
    "                                        xticks_rotation = 90,\n",
    "                                        ax = axes[0, 1])\n",
    "ConfusionMatrixDisplay.from_predictions(y_true_classes_vgg, y_pred_classes_vgg, \n",
    "                                        display_labels = report_labels,\n",
    "                                        xticks_rotation = 90,\n",
    "                                        ax = axes[1, 0])\n",
    "ConfusionMatrixDisplay.from_predictions(y_true_classes_vgg_finetune, y_pred_classes_vgg_finetune, \n",
    "                                        display_labels = report_labels,\n",
    "                                        xticks_rotation = 90,\n",
    "                                        ax = axes[1, 1])\n",
    "\n",
    "axes[0,0].set_title('Simple CNN')\n",
    "axes[0,1].set_title('CNN With Normalization')\n",
    "axes[1,0].set_title('VGG-16 - Feature Extraction')\n",
    "axes[1,1].set_title('VGG-16 - Fine-Tuned')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63abd667",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Simple CNN')\n",
    "print(classification_report(test_generator_aug.classes, y_pred_classes_conv, target_names = report_labels))\n",
    "print('--------------------------------------------------------')\n",
    "print('CNN With Regularization')\n",
    "print(classification_report(test_generator_aug.classes, y_pred_classes_conv_drop, target_names = report_labels))\n",
    "print('--------------------------------------------------------')\n",
    "print('VGG-16 - Feature Extraction')\n",
    "print(classification_report(test_generator_vgg.classes, y_pred_classes_vgg, target_names = report_labels))\n",
    "print('--------------------------------------------------------')\n",
    "print('Fine-Tuned VGG-16')\n",
    "print(classification_report(test_generator_vgg.classes, y_pred_classes_vgg_finetune, target_names = report_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a32c75",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "Overall, each of the four models above performed relatively well in terms of both accuracy and overall recall. The VGG-16 model using all of the pre-trained weights had the highest accuracy, but we can dig deeper into where each model went wrong and select our final model.\n",
    "\n",
    "The worst possible outcome for our model would be to predict that a person does not have a tumor when they actually do. We want our model to correctly the presence of a case as often as possible so the patient can follow up, receive a final diagnosis from their clinician, and start treatment appropriately. \n",
    "\n",
    "The VGG-16 model using pre-trained weights has the highest recall for the no tumor class at 99%, which means it correctly classified 99% of all the images with no tumor present in the dataset. Further, it has the highest precision for that class at 97%, meaning 97% of all of its predicted positives were true positives (and thus the fewest of its predicted \"no tumor\" images were actually images that showed a tumor). **Subsequently, we can select the VGG-16 feature extraction model as our final model because it performs better than the rest in terms of overall accuracy, and makes mistakes more rarely for the \"no tumor\" class than any other model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a643e247",
   "metadata": {},
   "source": [
    "### Examining Incorrect Predictions\n",
    "Now that we've selected a model, let's look more deeply at some of the incorrect predictions generated by that model to better understand what those images look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7370ff96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new df with test data and corresponding predictions\n",
    "tumor_test_df_preds = pd.concat([tumor_test_df, \n",
    "                            pd.Series(y_pred_classes_vgg, name = 'pred_label')], \n",
    "                            axis = 1)\n",
    "tumor_test_df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d6a3bb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# relabel predictions\n",
    "pred_dict = {0: 'glioma', 1: 'meningioma', 2: 'notumor', 3: 'other', 4: 'pituitary'}\n",
    "tumor_test_df_preds['pred_label'].replace(pred_dict, inplace = True)\n",
    "tumor_test_df_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fccc662",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create df with subset of only incorrect predictions\n",
    "wrong_preds = tumor_test_df_preds.loc[tumor_test_df_preds['label'] != \n",
    "                                      tumor_test_df_preds['pred_label']]\n",
    "wrong_preds.reset_index(drop = True, inplace = True)\n",
    "wrong_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c0697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open 16 images\n",
    "images = open_images(wrong_preds['paths'][0:17])\n",
    "labels = wrong_preds['label'][0:17]\n",
    "pred_labels = wrong_preds['pred_label'][0:17]\n",
    "fig = plt.figure(figsize=(12, 16))\n",
    "for x in range(1, 17):\n",
    "    fig.add_subplot(4, 4, x)\n",
    "    plt.axis('off')\n",
    "    plt.title(f'True: {labels[x]}\\n Predicted: {pred_labels[x]}')\n",
    "    plt.imshow(images[x])\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3a381",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save model for use in deployment\n",
    "vggmodel.save('/Users/eli/Desktop/brain_tumor_CNN_classifier/final_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
